## 実行方法
### 事前準備
- docker-composeが使えるようにしてください
- 環境変数を設定してください
  1. 設定する値の確認
      - OpenAIのAPIキー：`OPENAI_API_KEY`
      - プロキシ用変数(プロキシ環境でない場合は不要)：`HTTP_PROXY`, `HTTPS_PROXY`, `NO_PROXY`, `http_proxy`, `https_proxy`, `no_proxy`の6つ
      - huggingfaceのダウンロード用トークン（※ローカルLLMを使わない場合は不要）：`HUGGING_FACE_HUB_TOKEN`
  2. dockerのbuild用の設定
      - 【ホストマシンの管理権限がある場合】`/etc/systemd/system/docker.service.d/http-proxy.conf`に上記のプロキシ用変数を書いてください
      - 【ホストマシンの管理権限がない場合】`~/.docker/config.json`に上記のプロキシ用変数を書いてください
  3. dockerのrun用の設定
      - 【ホストマシンのユーザ設定を変えてもいい場合】`~/.bashrc`などで`export`を用いて、上記のOpenAIのAPIキー、プロキシ用変数、huggingfaceのダウンロード用トークンを設定してください
      - 【ホストマシンのユーザ設定を変えたくない場合】`don.env`ファイルを`.env`と名前を変えて、上記のOpenAIのAPIキー、プロキシ用変数、huggingfaceのダウンロード用トークンを設定してください

### インストール手順
1. 本プログラムをダウンロードし、ダウンロードしたフォルダに入ります
2. `docker compose up --build`を実行します
3. upが終わったら、ブラウザでURLの欄に次の値を入れて、ページが開けるか動作するか確認します：
   - `http://localhost`
   - `http://localhost/exec`

### 停止方法
1. 「Ctrl + C」を押して、停止します
2. 【オプション】次のいずれかを実行すればコンテナの削除ができます
   - `docker compose down`を実行する（dockerイメージは消えない）
   - `docker compose down --rmi all`を実行する（dockerイメージごと消せる）

### 開始方法
1. インストール手順とほぼ同じです。インストール手順の2番の実行を`docker compose up`と置き換えてください。
2. コンテナ起動後、以下の画面にアクセスして利用します。
    - 【閲覧者ユーザ用】ルーム設定画面: `http://localhost` もしくは `http://localhost/view`
    - 【実行者ユーザ用】ルーム設定画面: `http://localhost/exec`

## 接続できるページの説明
デモUIには、以下の3つの画面（ページ）を用意しています。ユーザは、これらの画面を操作することで議論の実行や閲覧をすることができます。

- [ルーム設定画面](#ルーム設定画面)
- [チャット画面](#チャット画面)
- [筆記画面](#筆記画面)

### ルーム設定画面
- ルーム設定画面とは、ルームの管理を行うための画面です。ルームとは、現実の人間たちの会議における「会議室」に相当するもので、デモUIはルームごとに独立した議論を保持します。
- ルーム設定画面では、ルームの作成・削除を行うことができ、現在存在しているルームを一覧表示で確認することができます。
- ルームの作成は、画面上部に設けられた入力フォームからルーム名を入力して行います。
- 作成されたルームは、ルーム設定画面中央に設けられたルーム一覧に表示されます。
- ルーム一覧に表示された行には、そのルームを操作・閲覧するための各種ボタンが表示されます。これらのボタンから、チャット画面への遷移・筆記画面への遷移・ルームの削除を行うことができます。
- なお、ユーザが閲覧者ユーザであった場合、ルームの作成と削除を行うことはできません。また、筆記画面に遷移することはできません。該当するボタン等の画面要素が非表示になります。
- また、実行者ユーザがすでにチャット画面か筆記画面にアクセスしている場合、他の実行者ユーザはチャット画面にも筆記画面にもアクセスすることができません。

### チャット画面
- チャット画面とは、議論の履歴全体をチャットアプリ形式で確認することができる画面です。
- チャット画面では、画面上部に設けられたフォームから議題・設定ファイルを入力し、議論の開始/停止(リセット)を実行することができます。
- 議論が始まると、画面中央にパネリストごとの発言が順番に表示されます。
- 議論が終わると、画面下部に設けられたフォームから新たな指示を入力できるようになります。このフォームから、入力した指示について追加で議論を実行することができます。

### 筆記画面
- 筆記画面とは、現在行われている議論をリアルタイムで確認することができる画面です。
- 筆記画面では、パネリストの行った発言が画面中央に表示されます。表示する際には音声による読み上げも行います。
- 議論が終わると、画面下部に設けられたフォームから新たな指示を入力できるようになります。このフォームから、入力した指示について追加で議論を実行することができます。

## フォルダ構成
### 概要
- nginx：HTTPサーバのnginxが入ってます。リバースプロキシを行い、frontendとbackendに繋ぎます。
- frontend：Webページの素材が入ってます。Next.js（Reactの亜種/進化版）とMUIで書かれています。
- backend：APIサーバが入ってます。pythonのライブラリであるFastAPIを利用する形で書かれています。LLMの操作に関するプログラムはここに入っています。

### 詳細
※は設定値を書き換えられるように準備されているファイルなどです

- `backend/`
  - `fast_api/` ← LLMエージェント発言多様化技術のAPIを構成する本体
    - `main.py` ← 各エンドポイントを定義
    - `connection_manager.py` ← LLMとのやりとりにおける接続を担う
    - `room_manager.py` ← ルーム管理用
    - `ai_constellation/`
      - `simulator/` ← 議論関連モジュール
        - `moderator.py` ← モデレータの設計（未実装）
        - `facilitator.py` ← ファシリテータの設計
        - `panelist.py` ← パネリストの設計
      -  `tech/` ← LLMエージェント発言多様化技術のサンプル実装である議論戦略構成器
         - `discussion_strategist.py` ← 議論戦略構成器のメインファイル
         - `strategist_config.yml` ← ※議論戦略構成器の設定用ファイル
      - `llm_clients/` ← LLMとの通信用クライアント
        - `base_client.py` ← クライアントの抽象クラス
        - `simple_client.py` ← OpenAI互換のクライアント
        - `models.yml` ← ※利用可能なLLMモデルを設定するファイル
      - `common/` ← 共通モジュールなどを定義
    - `configs/` ← ※会議設計に関する設定ファイル一覧
      - `agenda-list.yml` ← 議題一覧の設定ファイル
      - `config_1_en.yml` ← 選択用設定
      - `config_1_jp.yml` ← 選択用設定
      - `config_2_en.yml` ← 選択用設定
      - `config_2_jp.yml` ← 選択用設定
      - ...
    - `logs/` ← ログファイルを格納
    - `cache/` ← キャッシュファイルを格納
    - `Dockerfile` ← backendのDockerイメージの作成用設定ファイル
    - `requirements.txt` ← 使用するライブラリの管理ファイル
  - `llm_containers/` ← ローカルLLMのコンテナ資材など
- `frontend/`
  - `pages/` ← 接続可能な各ページの画面を格納
  - `components/` ← Reactのコンポーネントを格納
    - `Chat/` ← チャット画面の部分的なコンポーネントを格納
    - `Conversation/` ← 筆記画面の部分的なコンポーネントを格納
    - `SettingAndPanelist/` ← 議題等設定入力用のコンポーネントを格納
    - `Display/` ← 各ページの画面本体となるコンポーネントを格納
  - `hooks/` ← Reactのカスタムフックを格納
  - `public/` ← 画面描画で用いるフォントや画像を格納
  - `Dockerfile` ← frontendのDockerイメージの作成用設定ファイル
  - `next.config.js` ← Next.jsの設定ファイル
  - `package.json` ← 使用するライブラリの管理ファイル
- `nginx/`
  - `nginx.conf` ← リバースプロキシ設定
  - `Dockerfile` ← nginxのDockerイメージの作成用設定ファイル
- `docker-compose.yml` ← OpenAIのLLMのみ使う場合のコンテナ構成ファイル
- `docker-compose.local-llm.yml` ← ※ローカルLLMを使う場合のコンテナ構成ファイル（サンプル）
- `.env` ← ※コンテナ用の環境変数の設定ファイル

## 各種設定方法
LLMエージェント発言多様化技術の議論モジュールは以下のファイルを利用して動作します。

- [議題リストファイル](#議題リストファイル)
- [設定ファイル](#設定ファイル)
- [モデルファイル](#モデルファイル)
- [議論戦略構成ファイル](#議論戦略構成ファイル)

### 議題リストファイル
- 議題リストファイルは、議論モジュールで使用する議題を定義します。
- 議題リストファイルは、`backend/fast_api/configs`配下に、既定のファイル名で1個だけ作成します。
- 議題リストファイルの既定のファイル名は、`agenda-list.yml`です。

#### 議題リストファイルの形式
```yml
- id: <議題ID>
  ja: <議題(日本語版)>
  en: <議題(英語版)>
  display:
    ja: <画面表示用議題(日本語版)>
    en: <画面表示用議題(英語版)>
```

- `議題ID`: 議題を一意に識別するIDです。整数型で記載します。
- `議題(日本語版)`: 日本語で議論を開始する時に用いる議題です。文字列型で記載します。
- `議題(英語版)`: 英語で議論を開始する時に用いる議題です。文字列型で記載します。
- `画面表示用議題(日本語版)`: 画面に表示する際に用いる日本語での議題です。文字列型で記載します。
- `画面表示用議題(英語版)`: 画面に表示する際に用いる英語での議題です。文字列型で記載します。

#### 議論リストファイルの記載例
```yml
- id: 1
  ja: カーリング用のブラシは家の床掃除に使えるか？
  en: Are the brooms from curling good for using on house floors?
  display:
    ja: Q1：カーリング用のブラシは床の掃除に使えるか？
    en: Q1：Are the brooms from curling good for using on house floors?
- id: 2
  ja: 議題は「大牟田市における介護予防の方法のアイデア出し」です。それぞれの立場で2つずつアイデアを出し、その理由を合わせて説明してください。
  en: |-
    On the agenda is "ideas for ways to prevent caregiving in Omuta City."
    Each person should come up with two ideas from their own perspective and explain the reasons for their ideas together.
```

### 設定ファイル
- 設定ファイルは、議論に参加するパネリストや議論で用いるプロンプトについて定義します。
- 設定ファイルは、`backend/fast_api/configs`配下に、任意のファイル名で1個以上作成します。

#### 設定ファイルの形式
```yml
label: <ラベル>
user:
  name: <ユーザ名>
  image: <ユーザアバター画像>
  voice_id: <ユーザ音声ID>
  voice_pitch: <ユーザ音声ピッチ>
panelists:
  - name: <パネリスト名>
    model: <LLMベースモデル>
    persona: <パネリストペルソナ>
    characteristics: <パネリスト特徴>
    image: <パネリストアバター画像>
    voice_id: <パネリスト音声ID>
    voice_pitch: <パネリスト音声ピッチ>
system_prompt: <システムプロンプト>
first_user_prompt: <一次ユーザプロンプト>
subsequent_user_prompt: <二次ユーザプロンプト>
additional_first_user_prompt: <追加一次ユーザプロンプト>
additional_subsequent_user_prompt: <追加二次ユーザプロンプト>
additional_last_user_prompt: <追加最終ユーザプロンプト>
```

- `ラベル`: 設定ファイル名として画面に表示される文字列です。文字列型で記載します。
- `ユーザ名`: 画面に表示するユーザの名称です。文字列型で記載します（※この値には"ユーザ"または"User"を利用してください）
- `ユーザアバター画像`: ユーザ用のアバター画像までのパスです。画像ファイルまでのパスを記載します。文字列型で記載します。
- `ユーザ音声ID`: ユーザ用の読み上げ音声のIDです。筆記画面で利用します。整数値型で記載します。
- `ユーザ音声ピッチ`: ユーザ用の読み上げ音声のピッチです。筆記画面で利用します。浮動小数点数型で記載します。
- `パネリスト名`: 議論に参加させるパネリストの表示名です。文字列型で記載します。
- `LLMベースモデル`: パネリストとして動作するベースのLLMモデルです。文字列型で記載します。
- `パネリストペルソナ`: パネリストのペルソナです。文字列型で記載します。
- `パネリスト特徴`: パネリストの特徴を表す文章です。文字列型で記載します。
- `パネリストアバター画像`: パネリスト用のアバター画像です。画像ファイルまでのパスを記載します。文字列型で記載します。
- `パネリスト音声ID`: パネリスト用の読み上げ音声のIDです。筆記画面で利用します。整数値型で記載します。
- `パネリスト音声ピッチ`: パネリスト用の読み上げ音声のピッチです。筆記画面で利用します。浮動小数点数型で記載します。
- `システムプロンプト`: 議論実行時に使用される各パネリストへのシステムプロンプトです。文字列型で記載します。このプロンプト内には次の変数を記載することができます。
  - `${__persona__}`: パネリストペルソナ。
  - `${__characteristics__}`: パネリストの特徴。
- `一次ユーザプロンプト`: 議論開始時において、最初に発言するパネリストに指示するためのプロンプトです。文字列型で記載します。このプロンプト内には次の変数を記載することができます。
  - `${__current_agenda__}`: 議論開始時にユーザから入力された議題(指示内容)。
- `二次ユーザプロンプト`: 議論開始時において、2番目以降に発言するパネリストに指示するためのプロンプトです。文字列型で記載します。
  - `${__current_agenda__}`: 議論開始時にユーザから入力された議題(指示内容)。
  - `${__opponents_comments_on_current_agenda__}`: 議論開始時にユーザから入力された議題(指示内容)に対する他のパネリストの発言。
- `追加一次ユーザプロンプト`: 議論開始時以外の指示入力時(追加議論)において、最初に発言するパネリストに指示するためのプロンプトです。文字列型で記載します。
  - `${__last_agenda__}`: 一つ前の議題(指示内容)。
  - `${__opponents_comments_on_last_agenda__}`: 一つ前の議題(指示内容)における他のパネリストの発言。
- `追加二次ユーザプロンプト`: 議論開始時以外の指示入力時(追加議論)において、2番目以降に発言するパネリストに指示するためのプロンプトです。ただし、最後に発言するパネリストには、`追加最終ユーザプロンプト`が用いられます。文字列型で記載します。文字列型で記載します。
  - `${__last_agenda__}`: 一つ前の議題(指示内容)。
  - `${__opponents_comments_on_last_agenda__}`: 一つ前の議題(指示内容)における他のパネリストの発言。
  - `${__current_agenda__}`: 現在の議題(指示内容)。すなわち追加議論においてユーザが入力した最新の指示内容。
  - `${__opponents_comments_on_current_agenda__}`: 現在の議題(指示内容)における他のパネリストの発言。
- `追加最終ユーザプロンプト`: 議論開始時以外の指示入力時(追加議論)において、最後に発言するパネリストに指示するためのプロンプトです。文字列型で記載します。
  - `${__current_agenda__}`: 現在の議題(指示内容)。すなわち追加議論においてユーザが入力した最新の指示内容。
  - `${__opponents_comments_on_current_agenda__}`: 現在の議題(指示内容)における他のパネリストの発言。

#### 設定ファイルの記載例
```yml
label: GPT マルチエージェント
user:
  name: ユーザ
  image: /images/human_01.png
  voice_id: 1
  voice_pitch: 0.5
panelists:
- name: 医師（内科）
  persona: 医師（内科）
  characteristics: |-
    - 患者をトータルに見立てる家庭医（かかりつけ医）としての観点を持つ
    - 循環器の観点から議論に臨む
  image: /images/AI_01.png
  voice_id: 0
  voice_pitch: 0.5
- name: 作業療法士
  persona: 作業療法士
  characteristics: |-
    - 「食事」「入浴」「仕事・学習」など日常生活の作業遂行から精神面までの回復・維持・改善を図る観点を持つ
    - 介護者の社会参加の観点から議論に臨む
  image: /images/AI_02.png
  voice_id: 3
  voice_pitch: 0.5
system_prompt: |-
  あなたは大牟田市の地域コミュニティにおける会議の参加者です。
  会議には多数の参加者と一人の司会者がいます。
  議題は「大牟田市における介護予防の方法のアイデア出し」とその周辺の関連議題です。
  介護予防は、高齢者ができるだけ長く健康で自立した生活を送ることを目指し、要介護状態になるのを防ぐための取り組みを指します。

  あなたのペルソナは「${__persona__}」です。
  あなたは以下の特性を有します。
  ${__characteristics__}

  あなたの役割は、会議のパネリストとして、価値ある発言をすることです。
  自身のペルソナを意識しながら、議題に沿って司会者の指示に従った発言をしてください。
  過去に他者が出したアイディアと異なった観点を意識して、意見の重複ができるだけ無いようにアイデア出しを行ってください。
first_user_prompt: |-
  司会者の指示は「${__current_agenda__}」です。

  最初の話者として、司会者の指示に従い、あなたのペルソナや特性に基づいた、あなたならではの発言を行ってください。
  あなたは会議の一人目の発言者です。一人目の発言は会議の流れを決めるため肝心です。よく考えて発言してください。
subsequent_user_prompt: |-
  司会者の指示および他者の過去の発言は以下です。

  司会者の指示 : 「${__current_agenda__}」
  ${__opponents_comments_on_current_agenda__}

  続く話者として、司会者の指示に従い、あなたのペルソナや特性に基づいた、あなたならではの発言を行ってください。
  あなたの発言は後続にも影響を与えますのでよく考えて発言してください。
additional_first_user_prompt: |-
  司会者の指示および他者の過去の発言は以下です。

  司会者の指示 : 「${__last_agenda__}」
  ${__opponents_comments_on_last_agenda__}

  司会者の新たな指示は「${__current_agenda__}」です。

  最初の話者として、司会者の新たな指示に従い、あなたのペルソナや特性に基づいた、あなたならではの発言を行ってください。
  あなたは会議のこの指示の一人目の発言者です。一人目の発言は会議の流れを決めるため肝心です。よく考えて発言してください。
additional_subsequent_user_prompt: |-
  司会者の指示および他者の過去の発言は以下です。

  司会者の指示 : 「${__last_agenda__}」
  ${__opponents_comments_on_last_agenda__}
  司会者の新たな指示 : 「${__current_agenda__}」
  ${__opponents_comments_on_current_agenda__}

  続く話者として、司会者の新たな指示に従い、あなたのペルソナや特性に基づいた、あなたならではの発言を行ってください。
additional_last_user_prompt: |-
  司会者の指示および他者の過去の発言は以下です。

  司会者の新たな指示 : 「${__current_agenda__}」
  ${__opponents_comments_on_current_agenda__}

  続く話者として、司会者の新たな指示に従い、あなたのペルソナや特性に基づいた、あなたならではの発言を行ってください。
```

### モデルファイル
- モデルファイルは、議論モジュールで使用するモデルについて定義します。
- モデルファイルは、`backend/fast_api/ai_constellation/llm_clients`配下に、既定のファイル名で1個だけ作成します。
- モデルファイルの既定のファイル名は、`models.yml`です。

#### モデルファイルの形式
```yml
<モデルタグ>:
  version: <モデル名>
  api_key: <APIキー>
  organization: <登録組織ID>
  project: <登録プロジェクトID>
  base_url: <ベースURL>
  timeout: <タイムアウト秒数>
  max_retries: <最大リトライ数>
  default_headers: <デフォルトヘッダー>
  default_query: <デフォルトクエリパラメータ>
  strict_response_validation: <厳格応答バリデーションフラグ>
```

- `モデルタグ`: モデルの設定を一意に識別する任意の名前です。前述の設定ファイルで使用します。文字列型で記載します。必須です。
- `モデル名`: 使用するモデルの名前です。文字列型で記載します。必須です。
- `APIキー`: モデル利用に必要なAPIキーです。設定ファイル上にAPIキー情報を残したくない状況を想定して、本設定項目のみ`${環境変数}`の形式で環境変数を記載をすることができます。APIキーが不要なモデルに対しては省略可能です。
- `登録組織ID`: ユーザが登録している組織のIDです。文字列型で記載します。必須です。
- `登録プロジェクトID`: ユーザが登録しているプロジェクトのIDです。文字列型で記載します。省略可能です。
- `ベースURL`: 使用するモデルを配置したサーバのURLです。文字列型で記載します。省略可能です。
- `タイムアウト秒数`: モデルにアクセスする時にタイムアウトするまでの秒数です。浮動小数点数型か整数型で記載します。省略可能です。
- `最大リトライ数`: モデルへのアクセスが失敗した時にのリトライ数の上限です。整数型で記載します。省略可能です。
- `デフォルトヘッダー`: モデルへのHTTP/HTTPSリクエストに付与するヘッダーの初期値です。辞書型で記載します。省略可能です。
- `デフォルトクエリパラメータ`: モデルへのHTTP/HTTPSリクエストに付与するクエリパラメータの初期値です。辞書型で記載します。省略可能です。
- `厳格応答バリデーションフラグ`: モデルに応答に厳格なチェックを行うかどうかを決定するフラグです。省略可能です。

これらの値は、議論モジュール内部でOpenAIのSDKが提供する`OpenAI`クラスにそのまま渡されます。省略可能な値を省略した場合は、クラスの既定の初期値を用います。

#### モデルファイルの記載例
```yml
OpenAI:
  version: 'gpt-4o-2024-05-13'
  api_key: ${OPENAI_API_KEY}
  organization: your_organization_id
  project: your_project_id
  timeout: 5
  max_retries: 5
  strict_response_validation: true
tsuzumi-1.2:
  version: tsuzumi-7b-v1_2-8k-instruct
  base_url: 'http://fastchat-tsuzumi7B-v1.2-api-server:30000/v1'
  default_query:
    something_query_param_name: something_query_param_value
  default_headers:
    Authorization: 'Bearer 8859b0cb'
```

### 議論戦略構成ファイル
- 議論戦略構成ファイルは、LLMエージェント発言多様化技術のサンプル実装である議論戦略構成器の設定について定義します。
- 議論戦略構成ファイルは、`backend/fast_api/ai_constellation/tech`配下に、既定のファイル名で1個だけ作成します。
- 議論戦略構成ファイルの既定のファイル名は、`strategist_config.yml`です。

#### 議論戦略構成ファイルの形式
```yml
tail_prompts: <末尾プロンプトリスト>
state_names: <議論状態名リスト>
state_judge_prompt: <議論状態判断プロンプト>
legal_prompts_dict: <議論状態-プロンプト辞書>
embedding_model_name: <埋め込み用モデル名>
torch_device: <torchデバイス>
```

- `末尾プロンプトリスト`: 議論戦略構成器による介入を行う際、ユーザプロンプトの末尾に付与されるプロンプトです。文字列型のリストで記載します。
- `議論状態名リスト`: 議論戦略構成器が議論の状態を判定する時に用いるラベルです。「発散」や「収束」など、議論がどのような様態を取っているかを示します。文字列型のリストで記載します。議論状態によって介入パターンを限定する際に指定します。省略時には、議論状態の判定処理をスキップします。
- `議論状態判断プロンプト`: 議論戦略構成器が議論の状態を判定する時に用いるプロンプトです。文字列型記載します。このプロンプト内には次の変数を記載することができます。
  - `${__comments__}`: それまでの議論でのユーザ・パネリストの発言内容。
  - `${__options__}`: 議論状態名リスト。
- `議論状態-プロンプト辞書`: 議論の状態とその状態を取った時に使用することができる末尾プロンプトの組み合わせです。キーには議論の状態を文字列型で記載します。値には末尾プロンプトのインデックス番号を整数型のリストで記載します。議論状態戦略構成器は、はじめに判断した議論状態とこの辞書を照らし合わせ、使用可能な末尾プロンプトを取得します。この末尾プロンプトは複数取得される場合があります。議論状態戦略構成器は、それらの末尾プロンプトをユーザプロンプトに付与した上で議論状態に応じた応答を収集し、その中から最も良い応答を返却するように動作します。
- `埋め込み用モデル名`: 議論状態判断器と議論評価器で使われるLLMです(埋め込み用モデル)。文字列型で記載します。このモデルは、議論状態判断器では、議論状態名やLLMによる状態判断の結果を埋め込みベクトルに変換するために利用されます。議論評価器では、それまでの議論の発言内容を埋め込みベクトルに変換するために利用されます。
- `torchデバイス名`: 埋め込み用モデルを生成する際、PyTorchで利用されるGPU/CPUの設定値です。文字列型で記載します。入力できる文字列の仕様は、PyTorchの仕様に準拠します(`cpu`や`cuda`など)。

#### 議論戦略構成ファイルの記載例
```yml
tail_prompts: [
  '',
  '\nこれまでに登場した発言とは異なる観点から意見を出してください。',
  '\n意見が多様になるように注意して意見を出してください',
  '\nこれまで指摘された発言に対して、異なる理由を持って意見を出してください',
  '\n強烈に批判する方法を考え、意見を出してください。',
]
state_names: ['発散', '収束', '平行線', 'その他']
state_judge_prompt: |-
  以下の発言からなる議論は次の選択肢のうち、どの状態ですか？簡潔に答えてください。
  議論内容:
  ${__comments__}

  選択肢:
  ${__options__}
legal_prompts_dict: {
  '発散': [0, 1, 2, 3, 4],
  '収束': [0, 1, 2, 3, 4],
  '平行線': [0, 1, 2, 3, 4],
  'その他': [0, 1, 2, 3, 4],
}
embedding_model_name: llm-book/bert-base-japanese-v3-unsup-simcse-jawiki
torch_device: cpu
```

## ログの見方
LLMエージェント発言多様化技術の議論モジュールの動作ログは、`backend/fast_api/logs`ディレクトリ配下に出力されます。
`日時、モジュール名、ログレベル、ログ種別`の情報に続いて、それぞれのログ種別ごとに以下の情報がJSON形式で出力されます。
各ログ種別ごとの出力概要は、以下となります。
- `panelist_chat_log`: LLMとのこれまでの通信履歴の詳細
- `discussion_response_log`: LLMへの指示に対するレスポンスの簡易ログ
- `discussion_history_log`: 議論全体での会話履歴の一覧の簡易ログ
- `trial_log`: 議論戦略構成器のログ、複数のプロンプトを実行した際のLLMの返答結果とその評価値一覧のログ
